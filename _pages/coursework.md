---
layout: page
title: coursework
permalink: /coursework/
description: on this page I briefly elaborate on the courses that had great impacts on me and my thoughts on them. 
nav: true
nav_order: 7
---

**Graduate Courses:** I've taken six graduate courses. 

**<a href='https://sites.google.com/view/nikitazhivotovskiy/stat260?authuser=0'>Stat 260: Theoretical Statistics: Additional Chapters</a>**, Fall 2024, taught by **Prof. Nikita Zhivotovskiy**

  ---
  <p style="margin-left: 30px;"> &middot; Stein's unbiased risk estimate and its applications.</p>
  <p style="margin-left: 30px;"> &middot; Minimax lower bounds.</p>
  <p style="margin-left: 30px;"> &middot; RKHS theory and its relation to statistics.</p>
  <p style="margin-left: 30px;"> &middot; Sparse recovery.</p>
  <p style="margin-left: 30px;"> &middot; Elements of sampling theory.</p>
  <p style="margin-left: 30px;"> &middot; Analysis of interpolating estimators.</p>
  ---

**EE 229: Information Theory and Coding**, Fall 2024, taught by **Prof. Venkatachalam Anantharam**

  ---
  <p style="margin-left: 30px;"> &middot; Fundamental bounds of Shannon theory and their application.<p>
  <p style="margin-left: 30px;"> &middot; Source and channel coding theorems.<p>
  <p style="margin-left: 30px;"> &middot; Galois field theory, algebraic error-correction codes.<p>
  ---

**<a href='https://inst.eecs.berkeley.edu/~ee226a/sp24/'>EE 226A: Random Processes in Systems</a>**, Spring 2024, taught by **Prof. Anant Sahai**

  ---
  <p style="margin-left: 30px;"> &middot; Measure Theory, limit theorems and convergence.<p>
  <p style="margin-left: 30px;"> &middot; Gaussian random variables and processes.<p>
  <p style="margin-left: 30px;"> &middot; Linear estimation and time series analysis.<p>
  <p style="margin-left: 30px;"> &middot; Discrete and continuous time Markov Chains.<p>
  <p style="margin-left: 30px;"> &middot; Poisson process.<p>
  <p style="margin-left: 30px;"> &middot; Martingales.<p>
  ---

**<a href='https://www.stat.berkeley.edu/~ryantibs/statlearn-s24/'>Stat 241B: Advanced Topics in Statistical Learning</a>**, Spring 2024, taught by **Prof. Ryan Tibshirani**

  ---
  <p style="margin-left: 30px;"> &middot; Nearest neighbors and kernels.<p>
  <p style="margin-left: 30px;"> &middot; Splines and RKHS methods.<p>
  <p style="margin-left: 30px;"> &middot; Minimax theory.<p>
  <p style="margin-left: 30px;"> &middot; Empirical process theory.<p>
  <p style="margin-left: 30px;"> &middot; Lasso, Ridge and Ridgeless.<p>
  <p style="margin-left: 30px;"> &middot; Conformal prediction under distribution shift.<p>
  ---

**<a href='https://www.stat.berkeley.edu/~wfithian/courses/stat210a/'>Stat 210A: Theoretical Statistics</a>**, Fall 2023, taught by **Prof. Will Fithian**

  ---
  <p style="margin-left: 30px;"> &middot; Statistical decision theory (frequentist and Bayesian).<p>
  <p style="margin-left: 30px;"> &middot; Exponential families.<p>
  <p style="margin-left: 30px;"> &middot; Point estimation.<p>
  <p style="margin-left: 30px;"> &middot; Hypothesis testing.<p>
  <p style="margin-left: 30px;"> &middot; Resampling methods.<p>
  <p style="margin-left: 30px;"> &middot; Estimating equations and maximum likelihood.<p>
  <p style="margin-left: 30px;"> &middot; Empirical Bayes.<p>
  <p style="margin-left: 30px;"> &middot; Large-sample theory.<p>
  <p style="margin-left: 30px;"> &middot; High-dimensional testing, multiple testing and selective inference.<p>
  ---

  

Fall 2022 and spring 2024, I was fortunate to take the EECS 126/226 series, which covered different topics in probability and random processes. The prior was taught by my advisor <a href='https://people.eecs.berkeley.edu/~kannanr/'>Kannan</a>, and the latter was taught by professor <a href='https://www2.eecs.berkeley.edu/Faculty/Homepages/sahai.html'>Sahai</a>. The first third of 126 was a very fast-paced going through of measure-free probability. Kannan personally believed that it's more straightforward to teach probability without having to define sigma algebras and measures. We were fed with very difficult problems. The course then took a turn and quickly went through topics in stochastic processes, the most important ones of which are Markov chains and random graphs. We spent two lectures on information theory and a couple more on coding theory related topics. Then, the class concluded with estimation and testing. As a graduate version of 126, 226 kept most of its topics in alignment with 126, but there was actually barely any repetition. In the beginning we were just proving theorem in analysis and measure theory. It was actually quite exciting to see all the details in CLT and SLLN. The random processes were much more oriented toward the directions of our lab: things were introduced from a signal processing perspective. We had to deal with the statistical behaviors of different kinds of filters. Overall, these two classes were on top of my mind when I thought about which courses were to shape my education at Berkeley. Both professors were excellent in dilivering their lectures. They were mostly responsible for my decision to dedicate the majority of my portion of exploration to information and statistics related areas. 

Fall 2023, I took Stat 210A with 

